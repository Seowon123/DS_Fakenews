{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 🛠️ 어휘 다양성 계산 함수\n",
    "def calculate_lexical_diversity(text):\n",
    "    \"\"\"\n",
    "    텍스트에서 어휘 다양성을 계산합니다.\n",
    "    :param text: str, 분석할 텍스트\n",
    "    :return: 어휘 다양성 점수 (고유 단어 수 / 전체 단어 수)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return 0\n",
    "    words = text.split()  # 단어 단위로 분리\n",
    "    unique_words = set(words)  # 고유 단어 집합\n",
    "    lexical_diversity = len(unique_words) / len(words) if len(words) > 0 else 0\n",
    "    return lexical_diversity\n",
    "\n",
    "# 📂 JSON 파일로부터 데이터 로드 (Clickbait & NonClickbait 공통)\n",
    "def load_data_from_json(file_path, label):\n",
    "    \"\"\"\n",
    "    단일 JSON 파일에서 데이터를 로드합니다.\n",
    "    :param file_path: JSON 파일 경로\n",
    "    :param label: 1 (Clickbait) 또는 0 (Non-Clickbait)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if isinstance(data, list):\n",
    "            df = pd.DataFrame(data)\n",
    "        elif isinstance(data, dict):\n",
    "            df = pd.DataFrame(data.get('articles') or data.get('data') or data)\n",
    "        else:\n",
    "            print(f\"❌ 알 수 없는 JSON 구조입니다: {type(data)}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        if 'sourceDataInfo' in df.columns:\n",
    "            df['title'] = df['sourceDataInfo'].apply(lambda x: x.get('newsTitle', '') if isinstance(x, dict) else '')\n",
    "            df['content'] = df['sourceDataInfo'].apply(lambda x: x.get('newsContent', '') if isinstance(x, dict) else '')\n",
    "\n",
    "        df['label'] = label  # Clickbait = 1, NonClickbait = 0\n",
    "        return df[['title', 'content', 'label']]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {file_path} - {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 📂 데이터 경로 설정 (Clickbait & NonClickbait 단일 JSON 파일)\n",
    "clickbait_path = r'C:\\Ryuna\\ClickBait Detecting related data\\Training\\Labeling\\TL_Part1_Clickbait_Merged_SO\\merged_clickbait.json'\n",
    "nonclickbait_path = r'C:\\Ryuna\\ClickBait Detecting related data\\Training\\Labeling\\TL_Part1_NonClickbait_Merged_SO\\merged_file.json'\n",
    "\n",
    "\n",
    "# 🛠️ 데이터 불러오기\n",
    "print(\"📂 Clickbait 데이터 불러오는 중...\")\n",
    "clickbait_df = load_data_from_json(clickbait_path, label=1)  # Clickbait 데이터 로드\n",
    "\n",
    "print(\"📂 Non-Clickbait 데이터 불러오는 중...\")\n",
    "nonclickbait_df = load_data_from_json(nonclickbait_path, label=0)  # Non-Clickbait 데이터 로드\n",
    "\n",
    "# 🛠️ 데이터 병합\n",
    "df = pd.concat([clickbait_df, nonclickbait_df], ignore_index=True)\n",
    "print(f\"📚 데이터 병합 완료. 데이터 크기: {df.shape}\")\n",
    "\n",
    "# 🛠️ 어휘 다양성 및 추가 피처 계산\n",
    "print(\"📊 어휘 다양성 및 추가 피처 계산 중...\")\n",
    "\n",
    "# Title Lexical Diversity\n",
    "df['title_lexical_diversity'] = df['title'].apply(calculate_lexical_diversity)\n",
    "\n",
    "# Content Lexical Diversity\n",
    "df['content_lexical_diversity'] = df['content'].apply(calculate_lexical_diversity)\n",
    "\n",
    "# Combined Lexical Diversity (Title + Content)\n",
    "df['combined_text'] = df['title'] + ' ' + df['content']\n",
    "df['combined_lexical_diversity'] = df['combined_text'].apply(calculate_lexical_diversity)\n",
    "\n",
    "# Title Length (단어 수)\n",
    "df['title_length'] = df['title'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "\n",
    "# Content Length (단어 수)\n",
    "df['content_length'] = df['content'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "\n",
    "# 🔥 사용하지 않는 열 삭제\n",
    "df = df[['title_lexical_diversity', 'content_lexical_diversity', 'combined_lexical_diversity', \n",
    "         'title_length', 'content_length', 'label']]\n",
    "\n",
    "# 📘 데이터 저장\n",
    "output_path = r'D:\\머신러닝\\csv_files\\lexical_diversity_results_combined_naivebayes ver_1215.csv'  # 경로 수정\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"✅ 분석 결과가 '{output_path}'에 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
