{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, f1_score, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "## 2. 데이터 로드 및 전처리\n",
    "\n",
    "# JSON 데이터 로드 함수\n",
    "def read_json(folder_path):\n",
    "    dfs_source = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r') as file:\n",
    "                json_data = json.load(file)\n",
    "                dfs_source.append({\n",
    "                    \"newsTitle\": json_data[\"sourceDataInfo\"][\"newsTitle\"],\n",
    "                    \"newsContent\": json_data[\"sourceDataInfo\"][\"newsContent\"],\n",
    "                    \"clickbaitClass\": json_data[\"sourceDataInfo\"][\"useType\"]\n",
    "                })\n",
    "    return pd.DataFrame(dfs_source)\n",
    "\n",
    "folder_paths = [\n",
    "    r'.\\Training\\02.라벨링데이터\\TL_Part1_Clickbait_Auto_SO',\n",
    "    r'.\\Training\\02.라벨링데이터\\TL_Part1_Clickbait_Direct_SO',\n",
    "    r'.\\Training\\02.라벨링데이터\\TL_Part1_NonClickbait_Auto_SO'\n",
    "]\n",
    "\n",
    "# 데이터 통합\n",
    "frames = [read_json(folder) for folder in folder_paths]\n",
    "df_news = pd.concat(frames)\n",
    "\n",
    "# 한국어 불용어 로드\n",
    "def load_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read().splitlines()\n",
    "\n",
    "stopwords_path = \"stopwords-ko.txt\"\n",
    "korean_stopwords = load_stopwords(stopwords_path)\n",
    "\n",
    "# 텍스트 전처리 함수\n",
    "def preprocess_text(text, stop_words):\n",
    "    text = re.sub(r'[^가-힣\\s]', '', text)\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# 제목과 본문 전처리\n",
    "df_news['cleanedTitle'] = df_news['newsTitle'].apply(lambda x: preprocess_text(x, korean_stopwords))\n",
    "df_news['cleanedContent'] = df_news['newsContent'].apply(lambda x: preprocess_text(x, korean_stopwords))\n",
    "\n",
    "# 텍스트 길이 추가\n",
    "df_news['titleLength'] = df_news['cleanedTitle'].apply(len)\n",
    "df_news['contentLength'] = df_news['cleanedContent'].apply(len)\n",
    "\n",
    "\n",
    "## 3. 텍스트 분석 및 통계\n",
    "\n",
    "\n",
    "# TF-IDF 벡터화 및 유사도 계산\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_news['cleanedContent'])\n",
    "## 4. 모델 학습 및 평가\n",
    "\n",
    "# TF-IDF와 추가 feature 결합\n",
    "numeric_features = df_news[['titleLength', 'contentLength']].values\n",
    "tfidf_numeric_features = hstack((tfidf_matrix, numeric_features))\n",
    "\n",
    "\n",
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_numeric_features, df_news['clickbaitClass'], test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
